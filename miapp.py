
import os
import streamlit as st
from bokeh.models.widgets import Button
from bokeh.models import CustomJS
from streamlit_bokeh_events import streamlit_bokeh_events
from PIL import Image
import time
import glob

from gtts import gTTS
from googletrans import Translator

spoken_text = None


st.title("Â¿QuÃ© meme eres segÃºn como te sientes? ðŸ¥³")
st.subheader("Â¿CÃ³mo te sientes hoy?")

width, height = 200, 200

modo = st.radio("Bueno, empecemos por conocer cÃ³mo te sientes", ("Feliz", "Triste", "Enojado", "Preocupado", "Asustado"))
if modo == "Feliz":
    st.write("Â¡Que bien!ðŸ˜Š")
    image = Image.open("feliz.png")
    st.image(image)
if modo == "Triste":
    st.write("NOOOO Que pesar ðŸ˜”.")
    image2 = Image.open("triste.png")
    st.image(image2)
if modo == "Enojado":
    st.write("Que desafortunado ðŸ˜”.")
    image3 = Image.open("enojado.png")
    st.image(image3)
if modo == "Preocupado":
    st.write("Lo lamento mucho ðŸ˜”.")
    image4 = Image.open("preocupado.png")
    st.image(image4)
if modo == "Asustado":
    st.write("Esperemos que todo salga bien ðŸ˜”.")
    image5 = Image.open("asustado.png")
    st.image(image5)



# AUDIO A TEXTO
stt_button = Button(label=" COMENZAR ", width=200)

st.subheader("CuÃ©ntame mÃ¡s sobre la respuesta que esperas, Â¿quÃ© te gustarÃ­a ser? Una gallina sonriente, un gato enojado o tal vez homero simpson acostado en su cama...")
st.write("Apenas hundas sobre el botÃ³n, comienza a hablar:")

stt_button.js_on_event("button_click", CustomJS(code="""
    var recognition = new webkitSpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
 
    recognition.onresult = function (e) {
        var value = "";
        for (var i = e.resultIndex; i < e.results.length; ++i) {
            if (e.results[i].isFinal) {
                value += e.results[i][0].transcript;
            }
        }
        if ( value != "") {
            document.dispatchEvent(new CustomEvent("GET_TEXT", {detail: value}));
        }
    }
    recognition.start();
    """))

result = streamlit_bokeh_events(
    stt_button,
    events="GET_TEXT",
    key="listen",
    refresh_on_update=False,
    override_height=75,
    debounce_time=0)

if result:
    if "GET_TEXT" in result:
        spoken_text = result.get("GET_TEXT")
        st.write("Esto es lo que nos comentaste:", spoken_text)



#RECONOCIMIENTO DE EMOCIONES
from textblob import TextBlob
import streamlit as st

st.subheader("AsÃ­ interpretamos lo que dices:")
st.write("(Apenas me lo cuentes mediante el botÃ³n, lo analizaremos.")
st.write("")
st.write("Nos parece que pensamos esto:")


if spoken_text:
    blob = TextBlob(spoken_text)
    st.write('Polarity: ', round(blob.sentiment.polarity,2))
    st.write('Subjectivity: ', round(blob.sentiment.subjectivity,2))
    x = round(blob.sentiment.polarity,2)
    if x >= 0.5:
        st.write( 'Es un sentimiento Positivo ðŸ˜Š')
    elif x <= -0.5:
        st.write( 'Es un sentimiento Negativo ðŸ˜”')
    else:
        st.write( 'Es un sentimiento Neutral ðŸ˜')


st.write("")
st.write("")

#RECOMENDACIÃ“N
st.subheader("El meme que te asignamos el dÃ­a de hoy es: ")
if modo == "Feliz":
    image6 = Image.open("feliz meme.jpg")
    st.image(image6)
if modo == "Triste":
    image7 = Image.open("tristeza meme.jpg")
    st.image(image7)
if modo == "Enojado":
    image8 = Image.open("enojo meme.jpg")
    st.image(image8)
if modo == "Preocupado":
    image9 = Image.open("preocupado meme.jpg")
    st.image(image9)
if modo == "Asustado":
    image10 = Image.open("preocupado meme.jpg")
    st.image(image10)







